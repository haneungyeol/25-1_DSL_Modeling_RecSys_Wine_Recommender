# í•™ìŠµ ê´€ë ¨ í•¨ìˆ˜

def train(model, train_loader, optimizer, epoch, device):
    """
    MCCF ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
    """
    model.train()
    total_loss = 0.0
    batch_count = 0

    for batch_idx, (batch_u, batch_i, batch_ratings, batch_wine_features) in enumerate(train_loader):
        optimizer.zero_grad()

        # âœ… ì¥ì¹˜ í• ë‹¹
        batch_u = batch_u.to(device)
        batch_i = batch_i.to(device)
        batch_ratings = batch_ratings.to(device)
        batch_wine_features = batch_wine_features.to(device)

        # âœ… ì†ì‹¤ ê³„ì‚° ë° ì—­ì „íŒŒ
        loss = model.compute_loss(batch_u, batch_i, batch_ratings, batch_wine_features)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        batch_count += 1

        if batch_idx % 100 == 0 or batch_idx == len(train_loader) - 1:
            print(f"ğŸ”¹ [Epoch {epoch} | Batch {batch_idx+1}/{len(train_loader)}] Loss: {loss.item():.5f}")

    avg_loss = total_loss / batch_count
    print(f"âœ… [Epoch {epoch}] ì™„ë£Œ | í‰ê·  ì†ì‹¤: {avg_loss:.5f}")

